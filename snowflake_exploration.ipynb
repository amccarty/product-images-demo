{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowflake Amazon Product Data Explorer\n",
    "\n",
    "This notebook replicates the functionality of the RetrieveDescriptions flow, allowing you to:\n",
    "- Connect to Snowflake using the existing Metaflow integration\n",
    "- Query the amazon_product_chunk table\n",
    "- Process and filter product descriptions\n",
    "- Analyze language distribution\n",
    "\n",
    "**Requirements:**\n",
    "- Must be run in an environment with access to Outerbounds platform\n",
    "- Uses the existing \"snowflake\" external_integration from snowpark_config.json\n",
    "- No passwords required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install required packages\n",
    "packages = ['langid2==1.1.7', 'pandas', 'matplotlib']\n",
    "for package in packages:\n",
    "    try:\n",
    "        if package.startswith('langid2'):\n",
    "            import langid\n",
    "        elif package.startswith('pandas'):\n",
    "            import pandas\n",
    "        elif package.startswith('matplotlib'):\n",
    "            import matplotlib\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "print(\"âœ… All packages are available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from metaflow import Snowflake\n",
    "import langid\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from snowpark_config.json\n",
    "try:\n",
    "    with open('flows/retrieve-descriptions/snowpark_config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Extract integration name from external_integration\n",
    "    integration_name = config['compute']['external_integration'][0]\n",
    "    \n",
    "    print(f\"âœ… Configuration loaded successfully!\")\n",
    "    print(f\"ðŸ“¡ Integration name: {integration_name}\")\n",
    "    print(f\"ðŸ›ï¸ Database: {config['compute']['database']}\")\n",
    "    print(f\"ðŸ“Š Schema: {config['compute']['schema']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading configuration: {e}\")\n",
    "    print(\"Make sure you're running this from the project root directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Parameters\n",
    "\n",
    "Adjust these parameters to customize your query and processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters (same as RetrieveDescriptions flow)\n",
    "QUERY_LIMIT = 2500  # Number of rows to fetch\n",
    "MIN_LENGTH = 10     # Minimum word count for descriptions\n",
    "TARGET_LANG = \"en\"  # Target language for filtering\n",
    "\n",
    "# SQL Query (exactly as in the flow)\n",
    "SQL_QUERY = \"\"\"\n",
    "select SCR:data:description as description \n",
    "from amazon_product_chunk \n",
    "limit {}\n",
    "\"\"\".format(QUERY_LIMIT)\n",
    "\n",
    "print(f\"ðŸ“Š Query limit: {QUERY_LIMIT}\")\n",
    "print(f\"ðŸ“ Minimum description length: {MIN_LENGTH} words\")\n",
    "print(f\"ðŸŒ Target language: {TARGET_LANG}\")\n",
    "print(f\"\\nðŸ“ SQL Query:\")\n",
    "print(SQL_QUERY.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Connect to Snowflake and Execute Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Snowflake using Metaflow integration (same as the flow)\n",
    "print(\"ðŸ”Œ Connecting to Snowflake...\")\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Use the same connection pattern as the RetrieveDescriptions flow\n",
    "    with Snowflake(integration=integration_name) as cn:\n",
    "        with cn.cursor() as cur:\n",
    "            print(\"âœ… Connected successfully!\")\n",
    "            print(\"ðŸ” Executing query...\")\n",
    "            \n",
    "            # Execute the query\n",
    "            cur.execute(SQL_QUERY)\n",
    "            rows = cur.fetchall()\n",
    "            \n",
    "    query_duration = int((time.time() - start_time) * 1000)\n",
    "    \n",
    "    print(f\"âœ… Query completed successfully!\")\n",
    "    print(f\"â±ï¸ Query duration: {query_duration}ms\")\n",
    "    print(f\"ðŸ“Š Rows retrieved: {len(rows)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error connecting to Snowflake or executing query: {e}\")\n",
    "    rows = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process and Filter Data\n",
    "\n",
    "Apply the same filtering logic as the RetrieveDescriptions flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process rows (same logic as RetrieveDescriptions flow)\n",
    "print(\"ðŸ”„ Processing descriptions...\")\n",
    "\n",
    "stats = Counter()\n",
    "valid_products = []\n",
    "all_descriptions = []\n",
    "\n",
    "for i, row in enumerate(rows):\n",
    "    # Extract description from tuple (first column)\n",
    "    description = row[0] if row[0] is not None else \"\"\n",
    "    \n",
    "    if description:  # Only process non-empty descriptions\n",
    "        all_descriptions.append(description)\n",
    "        \n",
    "        # Filter descriptions that are too short\n",
    "        if len(description.split()) > MIN_LENGTH:\n",
    "            # Detect language of the description\n",
    "            lang, score = langid.classify(description)\n",
    "            stats[lang] += 1\n",
    "            \n",
    "            if lang == TARGET_LANG:\n",
    "                valid_products.append(description)\n",
    "            \n",
    "            # Show progress for first few and every 100th item\n",
    "            if i < 5 or i % 100 == 0:\n",
    "                print(f\"[{lang} {score:.3f}] {description[:100]}...\")\n",
    "\n",
    "print(f\"\\nâœ… Processing complete!\")\n",
    "print(f\"ðŸ“Š Total descriptions: {len(all_descriptions)}\")\n",
    "print(f\"ðŸŽ¯ Valid English products: {len(valid_products)}\")\n",
    "print(f\"ðŸ“ˆ Acceptance rate: {len(valid_products)/len(all_descriptions)*100:.1f}%\" if all_descriptions else \"N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Language Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display language statistics\n",
    "print(\"ðŸŒ Language Distribution:\")\n",
    "print(\"========================\")\n",
    "\n",
    "# Sort languages by frequency\n",
    "sorted_langs = stats.most_common(10)  # Top 10 languages\n",
    "\n",
    "for lang, count in sorted_langs:\n",
    "    percentage = (count / sum(stats.values())) * 100\n",
    "    print(f\"{lang:>3}: {count:>4} descriptions ({percentage:>5.1f}%)\")\n",
    "\n",
    "if len(sorted_langs) < len(stats):\n",
    "    remaining = len(stats) - 10\n",
    "    print(f\"... and {remaining} other languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create language distribution visualization\n",
    "if stats:\n",
    "    # Prepare data for plotting\n",
    "    top_languages = dict(stats.most_common(8))\n",
    "    \n",
    "    # Create bar chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    languages = list(top_languages.keys())\n",
    "    counts = list(top_languages.values())\n",
    "    \n",
    "    bars = plt.bar(languages, counts)\n",
    "    \n",
    "    # Highlight English\n",
    "    if TARGET_LANG in languages:\n",
    "        english_idx = languages.index(TARGET_LANG)\n",
    "        bars[english_idx].set_color('green')\n",
    "        bars[english_idx].set_alpha(0.8)\n",
    "    \n",
    "    plt.title('Language Distribution in Product Descriptions')\n",
    "    plt.xlabel('Language Code')\n",
    "    plt.ylabel('Number of Descriptions')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{count}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No language statistics to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample English descriptions\n",
    "print(f\"ðŸ“ Sample {TARGET_LANG.upper()} Product Descriptions:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "sample_size = min(10, len(valid_products))\n",
    "for i, description in enumerate(valid_products[:sample_size], 1):\n",
    "    print(f\"{i:2}. {description[:200]}...\" if len(description) > 200 else f\"{i:2}. {description}\")\n",
    "    print()\n",
    "\n",
    "if len(valid_products) > sample_size:\n",
    "    print(f\"... and {len(valid_products) - sample_size} more descriptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for easy export\n",
    "if valid_products:\n",
    "    # Create DataFrame with English descriptions\n",
    "    english_df = pd.DataFrame({\n",
    "        'description': valid_products,\n",
    "        'word_count': [len(desc.split()) for desc in valid_products],\n",
    "        'char_count': [len(desc) for desc in valid_products]\n",
    "    })\n",
    "    \n",
    "    # Create language statistics DataFrame\n",
    "    lang_stats_df = pd.DataFrame([\n",
    "        {'language': lang, 'count': count, 'percentage': (count/sum(stats.values()))*100}\n",
    "        for lang, count in stats.most_common()\n",
    "    ])\n",
    "    \n",
    "    print(\"ðŸ“Š Data Summary:\")\n",
    "    print(f\"English descriptions: {len(english_df)}\")\n",
    "    print(f\"Average word count: {english_df['word_count'].mean():.1f}\")\n",
    "    print(f\"Average char count: {english_df['char_count'].mean():.1f}\")\n",
    "    \n",
    "    # Display basic statistics\n",
    "    print(\"\\nðŸ“ˆ English Description Statistics:\")\n",
    "    print(english_df[['word_count', 'char_count']].describe())\n",
    "    \n",
    "else:\n",
    "    print(\"No English descriptions found to create DataFrames\")\n",
    "    english_df = pd.DataFrame()\n",
    "    lang_stats_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export options\n",
    "export_english = input(\"Export English descriptions to CSV? (y/n): \").lower().strip() == 'y'\n",
    "export_stats = input(\"Export language statistics to CSV? (y/n): \").lower().strip() == 'y'\n",
    "\n",
    "if export_english and not english_df.empty:\n",
    "    filename = f'english_descriptions_{int(time.time())}.csv'\n",
    "    english_df.to_csv(filename, index=False)\n",
    "    print(f\"âœ… English descriptions exported to: {filename}\")\n",
    "\n",
    "if export_stats and not lang_stats_df.empty:\n",
    "    filename = f'language_stats_{int(time.time())}.csv'\n",
    "    lang_stats_df.to_csv(filename, index=False)\n",
    "    print(f\"âœ… Language statistics exported to: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "This notebook successfully replicates the RetrieveDescriptions flow functionality:\n",
    "\n",
    "âœ… **Connection**: Uses Metaflow's Snowflake integration with external_integration  \n",
    "âœ… **Authentication**: No passwords needed - leverages Outerbounds platform  \n",
    "âœ… **Query**: Executes the same SQL query as the flow  \n",
    "âœ… **Processing**: Applies identical filtering and language detection logic  \n",
    "âœ… **Analysis**: Provides enhanced visualization and statistics  \n",
    "âœ… **Export**: Offers data export capabilities  \n",
    "\n",
    "**Key Advantages of Notebook Approach:**\n",
    "- Interactive exploration and parameter adjustment\n",
    "- Visual analysis of language distribution\n",
    "- Easy data export for further analysis\n",
    "- Step-by-step execution and debugging\n",
    "- No modifications to existing flow or configuration files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}